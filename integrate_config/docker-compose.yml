# docker compose run airflow-webserver airflow db init
# docker-compose run --rm integrate_config_airflow-webserver airflow db init
# docker run --rm \
#  --network=integrate_config_data-pipeline-net \
#  -e AIRFLOW__DATABASE__SQL_ALCHEMY_CONN='postgresql+psycopg2://airflow:airflow@postgres/airflow' \
#  apache/airflow:2.9.1 \
#  airflow db init
# docker run --rm \
#  --network=integrate_config_data-pipeline-net \
#  -e AIRFLOW__DATABASE__SQL_ALCHEMY_CONN='postgresql+psycopg2://airflow:airflow@postgres/airflow' \
#  apache/airflow:2.9.1 \
#  airflow users create \
#  --username eddi \
#  --firstname Sanghoon \
#  --lastname Lee \
#  --role Admin \
#  --email eddi@example.com \
#  --password eddi@123
version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    networks:
      - data-pipeline-net

  redis:
    image: redis:6
    networks:
      - data-pipeline-net

  airflow-webserver:
    image: apache/airflow:2.9.1
    restart: always
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__BROKER_URL: redis://redis:6379/0
      AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: "True"
    volumes:
      - ./dags:/opt/airflow/dags
    ports:
      - "8082:8080"
    command: >
      bash -c "pip install --no-cache-dir kafka-python && exec airflow webserver"
    networks:
      - data-pipeline-net

  airflow-scheduler:
    image: apache/airflow:2.9.1
    restart: always
    depends_on:
      - airflow-webserver
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__BROKER_URL: redis://redis:6379/0
    volumes:
      - ./dags:/opt/airflow/dags
    command: >
      bash -c "pip install --no-cache-dir kafka-python && exec airflow scheduler"
    networks:
      - data-pipeline-net

  airflow-flower:
    image: apache/airflow:2.9.1
    command: celery flower
    ports:
      - "5555:5555"
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # 추가
    depends_on:
      - redis
      - airflow-webserver
    networks:
      - data-pipeline-net

  zookeeper:
    container_name: zookeeper-container
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
    networks:
      - data-pipeline-net

  kafka:
    container_name: kafka
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9094:9094"
    environment:
#      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:29092
#      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,INTERNAL://kafka:29092,EXTERNAL://localhost:9094
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-container:2181
      KAFKA_CREATE_TOPICS: "test-topic:1:1,marketing.analysis.request:1:1"
    networks:
      - data-pipeline-net

networks:
  data-pipeline-net:
    driver: bridge

volumes:
  postgres-db-volume:
    driver: local
